<!doctype html>
<html lang="en"><head>
    <title>Deploying OpenStack in containers: Install and Upgrade</title>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <meta name="description" content="" />

    
    
    
    <link rel="stylesheet" href="../../../css/theme.min.css">

    
    
    

    
</head>
<body>
        <div id="content" class="mx-auto"><header class="container mt-sm-5 mt-4 mb-4 mt-xs-1">
    <div class="row">
        <div class="col-sm-4 col-12 text-sm-right text-center pt-sm-4">
            <a href="../../../" class="text-decoration-none">
                <img id="home-image" class="rounded-circle"
                    
                        src="../../../images/avatar.png"
                    
                />
            </a>
        </div>
        <div class="col-sm-8 col-12 text-sm-left text-center">
            <h2 class="m-0 mb-2 mt-4">
                <a href="../../../" class="text-decoration-none">
                    
                        Computers
                    
                </a>
            </h2>
            <p class="text-muted mb-1">
                
                    
                
            </p>
            <ul id="nav-links" class="list-inline mb-2">
                
                
                    <li class="list-inline-item">
                        <a class="badge badge-white " href="../../../about/" title="About">About</a>
                    </li>
                
                    <li class="list-inline-item">
                        <a class="badge badge-white " href="../../../posts/" title="Posts">Posts</a>
                    </li>
                
                    <li class="list-inline-item">
                        <a class="badge badge-white " href="../../../posts/archive/" title="Archives">Archives</a>
                    </li>
                
            </ul>
            <ul id="nav-social" class="list-inline">
                
                    <li class="list-inline-item mr-3">
                        <a href="http://github.com/shanecunningham" target="_blank">
                            <i class="fab fa-github fa-1x text-muted"></i>
                        </a>
                    </li>
                
                    <li class="list-inline-item mr-3">
                        <a href="" target="_blank">
                            <i class="fab fa-linkedin-in fa-1x text-muted"></i>
                        </a>
                    </li>
                
                    <li class="list-inline-item mr-3">
                        <a href="" target="_blank">
                            <i class="fab fa-twitter fa-1x text-muted"></i>
                        </a>
                    </li>
                
                    <li class="list-inline-item mr-3">
                        <a href="" target="_blank">
                            <i class="fas fa-at fa-1x text-muted"></i>
                        </a>
                    </li>
                
            </ul>
        </div>
    </div>
    <hr />
</header>
<div class="container">
    <div class="pl-sm-4 ml-sm-5">
        <p>My post on using <a href="https://github.com/stackforge/os-ansible-deployment">openstack-ansible</a> to deploy OpenStack in <a href="https://linuxcontainers.org/lxc/introduction/">LXC containers</a> in a two-node configuration with two NICs. One NIC is used for management, API and VM to VM traffic, the other NIC is for external network access. This is just for testing and messing around with deploying OpenStack in containers. An advantage to deploying with Ansible and containers is the easier upgrade path it provides. I&rsquo;ll show a simple example of that in place upgrade with going from Icehouse to Juno with just running a few playbooks.</p>
<p>###2 Nodes</p>
<p><strong>infra1</strong>:
Lenovo ThinkServer TS140
Xeon E3-1225 v3 3.2 GHz
8GB ECC RAM
2 x 1Gb NICs</p>
<!-- raw HTML omitted -->
<!-- raw HTML omitted -->
<p><strong>compute1</strong>:
Dell Poweredge T110II
Xeon E3-1230 v2 3.3 GHz
32GB ECC RAM
2 x 1Gb NICs</p>
<!-- raw HTML omitted -->
<!-- raw HTML omitted -->
<p>Template <a href="https://gist.github.com/shane-c/28afa426358406d59fbb">/etc/network/interfaces</a> and <a href="https://gist.github.com/shane-c/1f3600c6f3099e6b4b60">/etc/network/interfaces.d/openstack-interfaces.cfg</a></p>
<p>###Icehouse Install</p>
<p>We&rsquo;ll be deploying from the infra1 node, you could also have a dedicated &lsquo;deployment host&rsquo;, but for simplicity I deploy from infra1. Now we grab the version of openstack-ansible that will deploy Icehouse.</p>
<!-- raw HTML omitted -->
<!-- raw HTML omitted -->
<p>Edit your /etc/rpc_deploy/user_variables.yml and /etc/rpc_deploy/rpc_user_config.yml files which describe the environment. The following script can be used to generate user_variables.yml for service passwords.</p>
<!-- raw HTML omitted -->
<!-- raw HTML omitted -->
<p>You can see in the rpc_user_variables.yml file how you could add nodes if you had a larger deployment. This method of deploying OpenStack is designed for large deployments with multiple compute, cinder and swift nodes. For example, you can add more compute hosts like below.</p>
<!-- raw HTML omitted -->
<!-- raw HTML omitted -->
<p>Template <a href="https://gist.github.com/shane-c/f708f68fc597327d07a1">/etc/rpc_deploy/rpc_user_config.yml</a> and <a href="https://gist.github.com/shane-c/fa969ff78a110c4c23b4">/etc/rpc_deploy/user_variables.yml</a>. In addition to the OpenStack service settings and passwords, the user_variables.yml file can be used to integrate two services (Glance, Monitoring as a Service) with your public Rackspace cloud services. This is completely optional, you can still use the filesystem/NFS/NetApp for the glance backend and you don&rsquo;t have to install MaaS, but it gives you some additional options. For example, we can use <a href="http://www.rackspace.com/cloud/files">Cloud Files</a> which is based on OpenStack Swift for the Glance backend in our private cloud. We can also use the included MaaS playbooks to hook into the (free) <a href="http://www.rackspace.com/cloud/monitoring">Cloud Monitoring</a> service provided by Rackspace to monitor all of our hosts/containers/API services using the Cloud Monitoring API. The following values need to be setup in user_variables.yml if you want to integrate the two services with your public cloud account. Change to your own public cloud account details and you can choose which data center and container to store your Glance images in Cloud Files.</p>
<!-- raw HTML omitted -->
<!-- raw HTML omitted -->
<p>Now comes running the playbooks and Ansible will deploy OpenStack. These are the playbooks and order to run. Since we&rsquo;re not using a physical load balancer like an f5, we add the HAProxy playbook which will use our infra1 node as the load balancer for the environment.</p>
<ul>
<li>playbooks/setup/host-setup.yml</li>
<li>playbooks/infrastructure/haproxy-install.yml</li>
<li>playbooks/infrastructure/infrastructure-setup.yml</li>
<li>playbooks/openstack/openstack-setup.yml</li>
</ul>
<p>Hopefully each of these completes with zero items unreachable or failed. If you do receive a failure I usually rerun the playbook at least once and use -vvv to get more verbose output.</p>
<!-- raw HTML omitted -->
<!-- raw HTML omitted -->
<!-- raw HTML omitted -->
<!-- raw HTML omitted -->
<!-- raw HTML omitted -->
<!-- raw HTML omitted -->
<p><a href="http://docs.rackspace.com/rpc/api/v9/bk-rpc-installation/content/sec-playbooks-infrastructure-verify.html">Verify</a> the infrastructure playbook ran successfully. At this point you should be able to hit your Kibana interface at https://192.168.1.100:8443. The user is &lsquo;kibana&rsquo; and the password can be found in &lsquo;kibana_password&rsquo; in user_variables.yml.</p>
<p><a href="https://6dbddbf8e5efac8bed3b-f96466f7bd752d7ade3ea7b63a5a8dcd.ssl.cf1.rackcdn.com/kibana_icehouse.png"><img src="https://6dbddbf8e5efac8bed3b-f96466f7bd752d7ade3ea7b63a5a8dcd.ssl.cf1.rackcdn.com/kibana_icehouse.png" alt="kibana_icehouse"></a></p>
<p>Now we run the main OpenStack playbooks, these can take some time to complete.</p>
<!-- raw HTML omitted -->
<!-- raw HTML omitted -->
<p><a href="https://6dbddbf8e5efac8bed3b-f96466f7bd752d7ade3ea7b63a5a8dcd.ssl.cf1.rackcdn.com/horizon1.png"><img src="https://6dbddbf8e5efac8bed3b-f96466f7bd752d7ade3ea7b63a5a8dcd.ssl.cf1.rackcdn.com/horizon1.png" alt="horizon"></a></p>
<p>OpenStack should be installed!</p>
<p>###Monitoring as a Service</p>
<p>This is optional as far as deploying OpenStack is concerned, but it&rsquo;s a really nice way to monitor your hosts, containers and services (for free). Just setup your public Rackspace cloud account details in user_variables.yml and then run these playbooks. The playbooks will setup the monitoring agent and setup the checks for all hosts/containers/services, tying them to the notification plan you can create from <a href="https://intelligence.rackspace.com">https://intelligence.rackspace.com</a>. Click Notify and setup your notification plan. Then grab the notification ID, usually something like &lsquo;nphpgsP4DM&rsquo; which you can see in the URL. Enter that in the maas_notification_plan section in user_variables.yml. The only other thing you need to do is create an entity using the hostname for each server. From  <a href="https://intelligence.rackspace.com">https://intelligence.rackspace.com</a> just click Create Entity. The MaaS playbook and the Cloud Monitoring API will automatically use the entities as long as they match your servers hostnames.</p>
<!-- raw HTML omitted -->
<!-- raw HTML omitted -->
<!-- raw HTML omitted -->
<!-- raw HTML omitted -->
<!-- raw HTML omitted -->
<!-- raw HTML omitted -->
<!-- raw HTML omitted -->
<!-- raw HTML omitted -->
<p><a href="https://6dbddbf8e5efac8bed3b-f96466f7bd752d7ade3ea7b63a5a8dcd.ssl.cf1.rackcdn.com/maas1.png"><img src="https://6dbddbf8e5efac8bed3b-f96466f7bd752d7ade3ea7b63a5a8dcd.ssl.cf1.rackcdn.com/maas1.png" alt="maas_1"></a></p>
<p><a href="https://6dbddbf8e5efac8bed3b-f96466f7bd752d7ade3ea7b63a5a8dcd.ssl.cf1.rackcdn.com/maas3.png"><img src="https://6dbddbf8e5efac8bed3b-f96466f7bd752d7ade3ea7b63a5a8dcd.ssl.cf1.rackcdn.com/maas3.png" alt="maas_3"></a></p>
<p>Did I mention Cloud Monitoring is free? :D</p>
<p>###OpenStack Networking</p>
<p><strong>Note</strong>: Since we&rsquo;re not using VLANs I know the naming can be a bit confusing, I need to look into changing the naming since I believe the rpc_user_config.yml allows that. Traffic to a VMs floating IP enters the infra/network node on p4p1/br-vlan and the compute node accepts the traffic on em1/br-vxlan, so it&rsquo;s not truly segmented traffic. Fine for testing but I need to look into changing that up since there are two NICs on my servers.</p>
<p>The utility container is a helpful container with tools like the OpenStack clients installed. When interacting with the deployment you probably want to attach to the utility container and peform actions. I&rsquo;d also recommend setting up an alias that quickly connects to the utility container.</p>
<!-- raw HTML omitted -->
<!-- raw HTML omitted -->
<p>Here&rsquo;s what I did to setup two networks, one private for instance to instance traffic, and the other external for floating IPs. Our install should have put a file with our credentials at /root/openrc that we need to source to talk to our OpenStack installation.</p>
<!-- raw HTML omitted -->
<!-- raw HTML omitted -->
<p>Now you can add a floating IP to your tenant and assign it to an instance. You can do that from Horizon or the command line from the utility container. Use neutron floatingip-list, floatingip-create, port-list (or just use Horizon) to get the info you need. neutron floatingip-associate uses FLOATINGIP_ID PORT.</p>
<!-- raw HTML omitted -->
<!-- raw HTML omitted -->
<p>###In place upgrade to Juno</p>
<p>One of the main advantages to deploying with Ansible and inside LXC containers is the ability it gives you to perform in place upgrades. This is an extremely simplified example, of course, with only 2 nodes, and doesn&rsquo;t neccessarily reflect the upgrade complications of larger deployments. It&rsquo;s just a little demo, but still pretty impressive given the past issues with upgrading OpenStack.</p>
<p>First, let&rsquo;s verify what code base we&rsquo;re on.</p>
<!-- raw HTML omitted -->
<!-- raw HTML omitted -->
<p>We can verify the version from <a href="https://wiki.openstack.org/wiki/Releases,">https://wiki.openstack.org/wiki/Releases,</a> &lsquo;2014.1.3&rsquo; corresponds to the Icehouse release from Oct 2, 2014.</p>
<p>Now all we have to do is download the openstack-ansible Juno bits and rerun the  same playbooks. To check instances reaction to the upgrade I&rsquo;ll ping to and from a running instance during the upgrade. We can also check the API response time from our Cloud Monitoring MaaS.</p>
<!-- raw HTML omitted -->
<!-- raw HTML omitted -->
<p>As for the config files, the only change I made was removing <code>maas_repo_version</code> from user_variables.yml and deleting the alarms for the RabbitMQ checks from <a href="https://intelligence.rackspace.com">https://intelligence.rackspace.com</a>. We also need to copy the new rpc_enviroment.yml file into /etc/rpc_deploy/, for example, <code># cp /opt/os-ansible-deployment/etc/rpc_deploy/rpc_environment.yml /etc/rpc_deploy/</code>. Additional options and documentation can be found <a href="http://docs.rackspace.com/rpc/api/v10/bk-rpc-v10-releasenotes/content/rpc-upgrade-v9-v10.html">here</a>.</p>
<p>With the Juno openstack-ansible ready we run the following playbooks just like the Icehouse install.</p>
<!-- raw HTML omitted -->
<!-- raw HTML omitted -->
<!-- raw HTML omitted -->
<!-- raw HTML omitted -->
<!-- raw HTML omitted -->
<!-- raw HTML omitted -->
<p>Our monitoring system picked up some raises in API response time, but the only container that triggered an alarm was Horizon. It recovered on its own.</p>
<p>infra1 node CPU and RAM visuals during the upgrade.</p>
<p><a href="https://6dbddbf8e5efac8bed3b-f96466f7bd752d7ade3ea7b63a5a8dcd.ssl.cf1.rackcdn.com/maas_juno_infra1.png"><img src="https://6dbddbf8e5efac8bed3b-f96466f7bd752d7ade3ea7b63a5a8dcd.ssl.cf1.rackcdn.com/maas_juno_infra1.png" alt="maas_juno_infra1"></a></p>
<p>Keystone API during upgrade.</p>
<p><a href="https://6dbddbf8e5efac8bed3b-f96466f7bd752d7ade3ea7b63a5a8dcd.ssl.cf1.rackcdn.com/maas_juno_keystone.png"><img src="https://6dbddbf8e5efac8bed3b-f96466f7bd752d7ade3ea7b63a5a8dcd.ssl.cf1.rackcdn.com/maas_juno_keystone.png" alt="maas_juno_keystone"></a></p>
<p>Neutron API during upgrade.</p>
<p><a href="https://6dbddbf8e5efac8bed3b-f96466f7bd752d7ade3ea7b63a5a8dcd.ssl.cf1.rackcdn.com/maas_juno_nuetron.png"><img src="https://6dbddbf8e5efac8bed3b-f96466f7bd752d7ade3ea7b63a5a8dcd.ssl.cf1.rackcdn.com/maas_juno_nuetron.png" alt="maas_juno_neutron"></a></p>
<p>Nova API during upgrade.</p>
<p><a href="https://6dbddbf8e5efac8bed3b-f96466f7bd752d7ade3ea7b63a5a8dcd.ssl.cf1.rackcdn.com/maas_juno_nova.png"><img src="https://6dbddbf8e5efac8bed3b-f96466f7bd752d7ade3ea7b63a5a8dcd.ssl.cf1.rackcdn.com/maas_juno_nova.png" alt="maas_juno_nova"></a></p>
<p>Pinging to the running instance from my laptop during the upgrade.</p>
<!-- raw HTML omitted -->
<!-- raw HTML omitted -->
<p>Ping out from the instance to google.com during the upgrade.</p>
<!-- raw HTML omitted -->
<!-- raw HTML omitted -->
<p>And as you can see we&rsquo;re now running &lsquo;2014.2.1&rsquo; which is Juno, Dec 5, 2014 code.</p>
<!-- raw HTML omitted -->
<!-- raw HTML omitted -->
<p>That should be it. This was a very simple example of deploying and upgrading OpenStack into LXC containers using openstack-ansible, all done with editing a couple config files and runnning some playbooks, pretty awesome!</p>
<p>Icehouse docs: <a href="http://docs.rackspace.com/rpc/api/v9/bk-rpc-installation/content/rpc-common-front.html">http://docs.rackspace.com/rpc/api/v9/bk-rpc-installation/content/rpc-common-front.html</a>
Juno docs: <a href="http://docs.rackspace.com/rpc/api/v10/bk-rpc-installation/content/rpc-common-front.html">http://docs.rackspace.com/rpc/api/v10/bk-rpc-installation/content/rpc-common-front.html</a>
Upgrade docs: <a href="http://docs.rackspace.com/rpc/api/v10/bk-rpc-v10-releasenotes/content/rpc-common-front.html">http://docs.rackspace.com/rpc/api/v10/bk-rpc-v10-releasenotes/content/rpc-common-front.html</a>
openstack-ansible: <a href="https://launchpad.net/openstack-ansible">https://launchpad.net/openstack-ansible</a> &ndash; <a href="https://github.com/stackforge/os-ansible-deployment">https://github.com/stackforge/os-ansible-deployment</a>
Rackspace Private Cloud powered by OpenStack: <a href="http://www.rackspace.com/cloud/private/openstack">http://www.rackspace.com/cloud/private/openstack</a></p>

    </div>

            </div>
        </div><footer class="text-center pb-1">
    <small class="text-muted">
        
            &copy; Copyright 2021, Shane Cunningham
        
        <br>
        Powered by <a href="https://gohugo.io/" target="_blank">Hugo</a>
        and <a href="https://github.com/austingebauer/devise" target="_blank">Devise</a>
    </small>
</footer>
</body>
</html>
